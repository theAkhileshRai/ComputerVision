{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand gesture recognition Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwSJ324GxfZ8oJQqC4BpzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theAkhileshRai/ComputerVision/blob/master/Hand_gesture_recognition_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9hqB-WS_q5"
      },
      "source": [
        "#Tensorflow and Keras\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "# Import of keras model and hidden layers for our convolutional network\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
        "from keras.layers import Dense, Flatten, Dropout\r\n",
        "\r\n",
        "#Image handling libraries\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "#Sklearn libraries\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "#Initialize a list of paths for images\r\n",
        "imagepaths = []\r\n",
        "\r\n",
        "import os\r\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\r\n",
        "    for filename in filenames:\r\n",
        "        path = os.path.join(dirname, filename)\r\n",
        "        #print(os.path.join(dirname, filename))\r\n",
        "        if path.endswith(\"png\"):\r\n",
        "            imagepaths.append(path)\r\n",
        "\r\n",
        "print(len(imagepaths))\r\n",
        "#print(imagepaths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs060A7mTOEE"
      },
      "source": [
        "#Defining a function that plots the image selected from a path\r\n",
        "\r\n",
        "def img_plot(img_path):\r\n",
        "    img = cv2.imread(img_path)\r\n",
        "    #convert to RGB space\r\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "    #check the shape of the image\r\n",
        "    print(\"Shape of the image is \", img_rgb.shape)\r\n",
        "    #Display the image\r\n",
        "    plt.grid(False)\r\n",
        "    plt.imshow(img_rgb)\r\n",
        "    plt.xlabel(\"Width\")\r\n",
        "    plt.ylabel(\"Height\")\r\n",
        "    plt.title(\"Image \" + img_path)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-yfdxK8TR_4"
      },
      "source": [
        "#Example image plot\r\n",
        "#Plotting the first image from the dataset\r\n",
        "img_plot(imagepaths[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39OU5ia-TVbY"
      },
      "source": [
        "#### Creating Training Set and Labels ####\r\n",
        "# X for image data\r\n",
        "X = []\r\n",
        "# y for the labels\r\n",
        "y = []\r\n",
        "\r\n",
        "#Load the images into X by doing the necessary conversions and resizing of images\r\n",
        "#Resizing is done to reduce the size of image to increase the speed of training\r\n",
        "for path in imagepaths[:19999]:\r\n",
        "    img = cv2.imread(path)\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "    img = cv2.resize(img, (128,128))\r\n",
        "    X.append(img)  \r\n",
        "    #Getting the labels from the image path\r\n",
        "    category = path.split(\"/\")[7]\r\n",
        "    #print(category)\r\n",
        "    label = int(category.split(\"_\")[0][1])\r\n",
        "    #print(label)\r\n",
        "    y.append(label)\r\n",
        "\r\n",
        "#print(label)\r\n",
        "#Turning X & y into numpy arrays\r\n",
        "X = np.array(X)\r\n",
        "X = X.reshape(len(imagepaths[:19999]), 128, 128, 1)\r\n",
        "y = np.array(y)\r\n",
        "\r\n",
        "print(\"Images loaded: \", len(X))\r\n",
        "print(\"Labels loaded: \", len(y))\r\n",
        "\r\n",
        "\r\n",
        "print(y[0], imagepaths[0]) #To debug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7NtQrItTcck"
      },
      "source": [
        "# Make the test train split\r\n",
        "threshold = 0.3\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = threshold, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1s9YISkTtJ_"
      },
      "source": [
        "# Create a CNN Sequential Model\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (5,5), activation = 'relu', input_shape=(128,128,1)))\r\n",
        "model.add(MaxPooling2D((2,2)))\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu')) \r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Conv2D(128, (3, 3), activation='relu')) \r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Conv2D(128, (3, 3), activation='relu')) \r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDYn5OM6TwDv"
      },
      "source": [
        "#Model configuration for training purpose\r\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LVdBkp9Tx3N"
      },
      "source": [
        "\r\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=2, \r\n",
        "         validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS4oSeKCT0oa"
      },
      "source": [
        "model.save('handgesturerecog_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHxYRsl_T3uW"
      },
      "source": [
        "#calculate loss and accuracy on test data\r\n",
        "\r\n",
        "tLoss, tAccuracy = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "print('Test accuracy: {:2.2f}%'.format(tAccuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbNYfYEpT75m"
      },
      "source": [
        "# Making predictions on test data\r\n",
        "prediction = model.predict(X_test)\r\n",
        "#Lets compare the predicted value with actual label value\r\n",
        "# Ideally both prediction[0] and y_test[0] should be same\r\n",
        "np.argmax(prediction[0]), y_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htrLTcfcT_C3"
      },
      "source": [
        "# Function to plot images and labels for validation purposes\r\n",
        "def validate_gestures(predictions_array, true_label_array, img_array):\r\n",
        "  # Array for pretty printing and then figure size\r\n",
        "  class_names = [\"down\", \"palm\", \"l\", \"fist\", \"fist_moved\", \"thumb\", \"index\", \"ok\", \"palm_moved\", \"c\"] \r\n",
        "  plt.figure(figsize=(15,5))\r\n",
        "  \r\n",
        "  for i in range(1, 10):\r\n",
        "    # Just assigning variables\r\n",
        "    prediction = predictions_array[i]\r\n",
        "    true_label = true_label_array[i]\r\n",
        "    img = img_array[i]\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\r\n",
        "    \r\n",
        "    # Plot in a good way\r\n",
        "\r\n",
        "    plt.subplot(3,3,i)\r\n",
        "    plt.grid(False)\r\n",
        "    plt.xticks([])\r\n",
        "    plt.yticks([])\r\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\r\n",
        "\r\n",
        "    predicted_label = np.argmax(prediction) # Get index of the predicted label from prediction\r\n",
        "    \r\n",
        "    # Change color of title based on good prediction or not\r\n",
        "    if predicted_label == true_label:\r\n",
        "      color = 'blue'\r\n",
        "    else:\r\n",
        "      color = 'red'\r\n",
        "\r\n",
        "    plt.xlabel(\"Predicted: {} {:2.0f}% (Actual: {})\".format(class_names[predicted_label],\r\n",
        "                                  100*np.max(prediction),\r\n",
        "                                  class_names[true_label]),\r\n",
        "                                  color=color)\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdL0OI77UH9p"
      },
      "source": [
        "#Transform predictions into 1D array \r\n",
        "y_pred = np.argmax(prediction, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24p6jn1hULZu"
      },
      "source": [
        "#Create a Confusion Matrix for Evaluation\r\n",
        "# H = Horizontal\r\n",
        "# V = Vertical\r\n",
        "pd.DataFrame(confusion_matrix(y_test, y_pred), \r\n",
        "             columns=[\"Predicted Thumb Down\", \"Predicted Palm (H)\", \"Predicted L\", \"Predicted Fist (H)\", \"Predicted Fist (V)\", \"Predicted Thumbs up\", \"Predicted Index\", \"Predicted OK\", \"Predicted Palm (V)\", \"Predicted C\"],\r\n",
        "             index=[\"Actual Thumb Down\", \"Actual Palm (H)\", \"Actual L\", \"Actual Fist (H)\", \"Actual Fist (V)\", \"Actual Thumbs up\", \"Actual Index\", \"Actual OK\", \"Actual Palm (V)\", \"Actual C\"])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}